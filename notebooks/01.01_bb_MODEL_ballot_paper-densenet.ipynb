{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Folder Locations\n",
    "TEST_IMAGE_FOLDER = '../data/raw/Test/testset/'\n",
    "TEST_CSV = '../data/raw/Test/testset.csv'\n",
    "\n",
    "TRAIN_IMAGE_FOLDER = '../data/raw/Train/testset/'\n",
    "TRAIN_CSV = '../data/raw/Train/testset.csv'\n",
    "\n",
    "\n",
    "# VALID_IMAGE_FOLDER = '../data/raw/Train/testset/'\n",
    "# VALID_CSV = '../data/raw/Valid/new_valid_set.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600795.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>627152.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119963.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>118264.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199420.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data  Label\n",
       "0  600795.jpeg     10\n",
       "1  627152.jpeg     10\n",
       "2  119963.jpeg     10\n",
       "3  118264.jpeg     10\n",
       "4  199420.jpeg     10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(TRAIN_CSV)\n",
    "test_set = pd.read_csv(TEST_CSV)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>632755.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>496855.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>155390.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>265013.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>496360.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Data  Label\n",
       "0  632755.jpeg     10\n",
       "1  496855.jpeg     10\n",
       "2  155390.jpeg     10\n",
       "3  265013.jpeg     10\n",
       "4  496360.jpeg     10"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_set['Label'] = test_set['Label'].apply(str)\n",
    "train_set['Label'] = train_set['Label'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Data</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>3764</th>\n",
       "      <td>932784.jpeg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>3111</th>\n",
       "      <td>383133.jpeg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>4</th>\n",
       "      <td>199420.jpeg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>5764</th>\n",
       "      <td>271118.jpeg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>5220</th>\n",
       "      <td>251601.jpeg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Data Label\n",
       "Label                        \n",
       "0     3764  932784.jpeg     0\n",
       "1     3111  383133.jpeg     1\n",
       "10    4     199420.jpeg    10\n",
       "11    5764  271118.jpeg    11\n",
       "12    5220  251601.jpeg    12"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_test_data = train_set.groupby('Label').apply(lambda x: x.sample(1))\n",
    "single_test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(single_test_data['Label'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2609 entries, 0 to 2608\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Data    2609 non-null   object\n",
      " 1   Label   2609 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 40.9+ KB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = len(train_set['Label'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.,validation_split=0.25)\n",
    "#                            zoom_range=0.2,rotation_range = 5,\n",
    "#                            horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 validated image filenames belonging to 48 classes.\n",
      "Found 7200 validated image filenames belonging to 48 classes.\n",
      "Found 2400 validated image filenames belonging to 48 classes.\n",
      "Found 2609 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "TARGET_SIZE=(224, 224)\n",
    "\n",
    "single_test_data=datagen.flow_from_dataframe(\n",
    "dataframe=single_test_data,\n",
    "directory=TRAIN_IMAGE_FOLDER,\n",
    "x_col=\"Data\",\n",
    "y_col=\"Label\",\n",
    "subset=\"training\",\n",
    "seed=RANDOM_STATE,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "batch_size = 32,\n",
    "target_size=TARGET_SIZE)\n",
    "\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train_set,\n",
    "directory=TRAIN_IMAGE_FOLDER,\n",
    "x_col=\"Data\",\n",
    "y_col=\"Label\",\n",
    "subset=\"training\",\n",
    "seed=RANDOM_STATE,\n",
    "shuffle=True,\n",
    "class_mode=\"categorical\",\n",
    "batch_size = 32,\n",
    "target_size=TARGET_SIZE)\n",
    "\n",
    "\n",
    "valid_generator=datagen.flow_from_dataframe(\n",
    "dataframe=train_set,\n",
    "directory=TRAIN_IMAGE_FOLDER,\n",
    "x_col=\"Data\",\n",
    "y_col=\"Label\",\n",
    "subset=\"validation\",\n",
    "seed=RANDOM_STATE,\n",
    "shuffle=True,\n",
    "batch_size = 32,\n",
    "class_mode=\"categorical\",\n",
    "target_size=TARGET_SIZE)\n",
    "\n",
    "\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_set,\n",
    "directory=TEST_IMAGE_FOLDER,\n",
    "x_col=\"Data\",\n",
    "y_col=None,\n",
    "seed=RANDOM_STATE,\n",
    "shuffle=False,\n",
    "class_mode=None,\n",
    "batch_size = 32,\n",
    "target_size=TARGET_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_SIZE[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DENSENET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import regularizers, optimizers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow\n",
    "# create the base pre-trained model\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3), pooling='avg')\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "        \n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = Dense(1000, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(500, kernel_regularizer=regularizers.l1_l2(0.01), activity_regularizer=regularizers.l2(0.01))(x)\n",
    "x = Activation('relu')(x)\n",
    "predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "# model.fit(...)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.n//train_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "225/225 [==============================] - 88s 390ms/step - loss: 40.5193 - categorical_accuracy: 0.0247 - val_loss: 15.1210 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "225/225 [==============================] - 89s 395ms/step - loss: 11.2266 - categorical_accuracy: 0.0249 - val_loss: 16.8101 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "225/225 [==============================] - 89s 395ms/step - loss: 11.2183 - categorical_accuracy: 0.0271 - val_loss: 17.0653 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "225/225 [==============================] - 89s 395ms/step - loss: 11.2144 - categorical_accuracy: 0.0278 - val_loss: 17.2476 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "225/225 [==============================] - 89s 394ms/step - loss: 11.2131 - categorical_accuracy: 0.0288 - val_loss: 17.3384 - val_categorical_accuracy: 0.0000e+00\n",
      "INFO:tensorflow:Assets written to: filename.model/assets\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 32\n",
    "STEPS_PER_EPOCH = train_generator.n//train_generator.batch_size,\n",
    "VALIDATION_STEPS = 64,\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "# EPOCHS = 10\n",
    "# BATCH_SIZE = 32\n",
    "# STEPS_PER_EPOCH = single_test_data.n//single_test_data.batch_size,\n",
    "# # VALIDATION_STEPS = 64,\n",
    "# # STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "MODEL_FILE = 'filename.model'\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    #steps_per_epoch=STEPS_PER_EPOCH\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=STEP_SIZE_VALID)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "model.save(MODEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # at this point, the top layers are well trained and we can start fine-tuning\n",
    "# # convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# # and train the remaining top layers.\n",
    "\n",
    "# # let's visualize layer names and layer indices to see how many layers\n",
    "# # we should freeze:\n",
    "# for i, layer in enumerate(base_model.layers):\n",
    "#    print(i, layer.name)\n",
    "\n",
    "# # we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# # the first 249 layers and unfreeze the rest:\n",
    "# for layer in model.layers[:249]:\n",
    "#    layer.trainable = False\n",
    "# for layer in model.layers[249:]:\n",
    "#    layer.trainable = True\n",
    "\n",
    "# # we need to recompile the model for these modifications to take effect\n",
    "# # we use SGD with a low learning rate\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "# model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# # we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# # alongside the top Dense layers\n",
    "# model.fit(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
